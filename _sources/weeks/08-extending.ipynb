{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 8 Notebook: Extending the Model\n",
    "===============================================================\n",
    "\n",
    "This week, we will look at graph neural networks using the PyTorch Geometric library: <https://pytorch-geometric.readthedocs.io/>. See {cite}`PyTorchGeometric` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('definitions.yml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    definitions = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "features = definitions['features']\n",
    "spectators = definitions['spectators']\n",
    "labels = definitions['labels']\n",
    "\n",
    "nfeatures = definitions['nfeatures']\n",
    "nspectators = definitions['nspectators']\n",
    "nlabels = definitions['nlabels']\n",
    "ntracks = definitions['ntracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphDataset import GraphDataset\n",
    "file_names = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root']\n",
    "graph_dataset = GraphDataset('data', features, labels, spectators, n_events=1000, n_events_merge=1000, \n",
    "                             file_names=file_names)\n",
    "file_names_test = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root']\n",
    "test_dataset = GraphDataset('data', features, labels, spectators, n_events=2000, n_events_merge=1000, \n",
    "                             file_names=file_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import EdgeConv, global_mean_pool\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "\n",
    "class EdgeBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeBlock, self).__init__()\n",
    "        self.edge_mlp = Seq(Lin(48*2, 128), \n",
    "                            ReLU(),\n",
    "                            Lin(128, 128))\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        out = torch.cat([src, dest], 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "class NodeBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NodeBlock, self).__init__()\n",
    "        self.node_mlp_1 = Seq(Lin(48+128, 128), \n",
    "                              ReLU(), \n",
    "                              Lin(128, 128))\n",
    "        self.node_mlp_2 = Seq(Lin(48+128, 128), \n",
    "                              ReLU(), \n",
    "                              Lin(128, 128))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        row, col = edge_index\n",
    "        out = torch.cat([x[row], edge_attr], dim=1)\n",
    "        out = self.node_mlp_1(out)\n",
    "        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        return self.node_mlp_2(out)\n",
    "\n",
    "    \n",
    "class GlobalBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalBlock, self).__init__()\n",
    "        self.global_mlp = Seq(Lin(128, 128), \n",
    "                              ReLU(), \n",
    "                              Lin(128, 2))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        out = scatter_mean(x, batch, dim=0)\n",
    "        return self.global_mlp(out)\n",
    "\n",
    "\n",
    "class InteractionNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InteractionNetwork, self).__init__()\n",
    "        self.interactionnetwork = MetaLayer(EdgeBlock(), NodeBlock(), GlobalBlock())\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x, edge_attr, u = self.interactionnetwork(x, edge_index, None, None, batch)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InteractionNetwork().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model,loader,total,batch_size):\n",
    "    model.eval()\n",
    "    \n",
    "    xentropy = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    sum_loss = 0.\n",
    "    t = tqdm(enumerate(loader),total=total/batch_size)\n",
    "    for i,data in t:\n",
    "        data = data.to(device)\n",
    "        y = torch.argmax(data.y,dim=1)\n",
    "        batch_output = model(data.x, data.edge_index, data.batch)\n",
    "        batch_loss_item = xentropy(batch_output, y).item()\n",
    "        sum_loss += batch_loss_item\n",
    "        t.set_description(\"loss = %.5f\" % (batch_loss_item))\n",
    "        t.refresh() # to show immediately the update\n",
    "\n",
    "    return sum_loss/(i+1)\n",
    "\n",
    "def train(model, optimizer, loader, total, batch_size):\n",
    "    model.train()\n",
    "    \n",
    "    xentropy = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    sum_loss = 0.\n",
    "    t = tqdm(enumerate(loader),total=total/batch_size)\n",
    "    for i,data in t:\n",
    "        data = data.to(device)\n",
    "        y = torch.argmax(data.y,dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(data.x, data.edge_index, data.batch)\n",
    "        batch_loss = xentropy(batch_output, y)\n",
    "        batch_loss.backward()\n",
    "        batch_loss_item = batch_loss.item()\n",
    "        t.set_description(\"loss = %.5f\" % batch_loss_item)\n",
    "        t.refresh() # to show immediately the update\n",
    "        sum_loss += batch_loss_item\n",
    "        optimizer.step()\n",
    "    \n",
    "    return sum_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataListLoader, Batch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def collate(items):\n",
    "    l = sum(items, [])\n",
    "    return Batch.from_data_list(l)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "valid_frac = 0.20\n",
    "full_length = len(graph_dataset)\n",
    "valid_num = int(valid_frac*full_length)\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset, valid_dataset = random_split(graph_dataset, [full_length-valid_num,valid_num])\n",
    "\n",
    "train_loader = DataListLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "train_loader.collate_fn = collate\n",
    "valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "valid_loader.collate_fn = collate\n",
    "test_loader = DataListLoader(test_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "test_loader.collate_fn = collate\n",
    "\n",
    "\n",
    "train_samples = len(train_dataset)\n",
    "valid_samples = len(valid_dataset)\n",
    "test_samples = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os.path as osp\n",
    "\n",
    "n_epochs = 20\n",
    "stale_epochs = 0\n",
    "best_valid_loss = 99999\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    loss = train(model, optimizer, train_loader, train_samples, batch_size)\n",
    "    valid_loss = test(model, valid_loader, valid_samples, batch_size)\n",
    "    print('Epoch: {:02d}, Training Loss:   {:.4f}'.format(epoch, loss))\n",
    "    print('           Validation Loss: {:.4f}'.format(valid_loss))\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        modpath = osp.join('interactionnetwork_best.pth')\n",
    "        print('New best model saved to:',modpath)\n",
    "        torch.save(model.state_dict(),modpath)\n",
    "        stale_epochs = 0\n",
    "    else:\n",
    "        print('Stale epoch')\n",
    "        stale_epochs += 1\n",
    "    if stale_epochs >= patience:\n",
    "        print('Early stopping after %i stale epochs'%patience)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "t = tqdm(enumerate(test_loader),total=test_samples/batch_size)\n",
    "y_test = []\n",
    "y_predict = []\n",
    "for i,data in t:\n",
    "    data = data.to(device)    \n",
    "    batch_output = model(data.x, data.edge_index, data.batch)    \n",
    "    y_predict.append(batch_output.cpu().numpy())\n",
    "    y_test.append(data.y.cpu().numpy())\n",
    "y_test = np.concatenate(y_test)\n",
    "y_predict = np.concatenate(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
